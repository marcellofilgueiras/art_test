# -*- coding: utf-8 -*-
"""data_modelling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B9BiEFsIfHUy7mrh9-Dq8QO_eqXlKfp1
"""

from google.colab import drive

# montar o drive pra ter acesso a
# arquivos do drive
drive.mount('/content/drive')

# olá valentim isso é uma nova célula

import pandas as pd

pd.read_csv("/content/drive/MyDrive/py/data/breast_cancer.csv")

"""**data_modeling**


Em um script ou jupyter notebook explore o dataset fornecido no arquivo breast_cancer.csv de forma a responder as completar o checklist a seguir.
O conjunto de dados "Breast Cancer Wisconsin (Diagnostic)" contém características extraídas dos exames de diagnóstico de câncer de mama, obtidas a partir de imagens digitalizadas das células, e a resposta, se o tumor é maligno ou benigno.
Do total de variáveis, foi feita uma seleção inicial, que levou às colunas

•Pontos côncavos médios: mean concave points;

•Perímetro médio: mean perimeter

•Dimensão fractal média: mean fractal dimension

•Pior perímetro: worst perimeter

•Pior textura: worst texture

•Pior área: worst area

•Tipo: target (1: benigno, 0: maligno).

1 – Investigue a associação de cada uma dessas variáveis com o tipo de tumor via análise exploratória de dados. Comente os resultados obtidos. (sugestão: boxplots, coeficientes de correlação, pairplot...)


"""

# Importação de bibliotecas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings


# 1. Importação e Preparação dos Dados
df = pd.read_csv("/content/drive/MyDrive/py/data/breast_cancer.csv")[['mean_concave_points', 'mean_perimeter',
                                         'mean_fractal_dimension', 'worst_perimeter',
                                         'worst_texture', 'worst_area', 'target']]

df['target_fact'] = df['target'].astype('category')
df['target_num'] = df['target'].astype(int)

# 2. Análise Exploratória de Dados
print("\nEstatísticas Descritivas:")
print(df.describe())

# Criar df_long com a função melt
df_long = df.melt(id_vars=['target_fact'],
                 value_vars=['mean_concave_points', 'mean_perimeter',
                            'mean_fractal_dimension', 'worst_perimeter',
                            'worst_texture', 'worst_area'],
                 var_name='variavel',
                 value_name='valor')

print(df_long)

plt.figure(figsize=(14, 8))

# Criar o boxplot facetado por variável
g = sns.catplot(
    x='target_fact',
    y='valor',
    col='variavel',  # Facet por variável
    data=df_long,
    kind='box',
    sharey=False,    # Cada subplot com escala independente
    col_wrap=3,      # 3 colunas de gráficos
    height=5,
    aspect=0.8,
    palette={'0': '#F8766D', '1': '#00BFC4'}
)


g.set_titles("{col_name}")  # Títulos dos facets
g.fig.suptitle('Distribuição das Variáveis por Tipo de Tumor', y=1.05, fontsize=16)
g.set_axis_labels("Tipo de Tumor", "Valor")

# Ajustar os rótulos do eixo X
for ax in g.axes.flat:
    ax.set_xticklabels(['Maligno', 'Benigno'])
    ax.grid(axis='y', linestyle='--', alpha=0.3)

plt.tight_layout()
plt.show()

"""df_melt"""

df_long

# Histogramas

# g é um objeto, e é um df preparando dados
g = sns.FacetGrid(df_long,
                  col='variavel',
                  hue='target_fact',
                  col_wrap=3,
                  sharex=False, sharey=False)
# Torne o
g.map(sns.histplot,
      'valor',
      #Mude esses aspectos de visuais
      alpha=0.6, bins=30)
# Adicione Legenda no gráfico g
g.add_legend()
# titulo na parte supeiror
plt.suptitle('Distribuição das Variáveis por Tipo de Tumor', y=1.02)
# mostre o gráfico
plt.show()

# Matriz de correlação
corr_matrix = df[df.columns[:-3]].corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Matriz de Correlação')
plt.xticks(rotation=45)
plt.show()

# Pairplot (Gráfico de pares)
sns.pairplot(df, vars=df.columns[:-3], hue='target_fact', diag_kind='hist', plot_kws={'alpha':0.5})
plt.suptitle('Relações entre Variáveis', y=1.02)
plt.show()

"""2 – Construa uma regressão linear para prever o tipo do tumor, indique as variaveis preditoras e as com significancia marginal neste modelo. Dica, utilize o modulo “OLS” do “statsmodels”. Comente os resultados obtidos.

 import statsmodels as sm
 res = sm.OLS(y, x).fit()
 print(res.summary())

"""

from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import roc_auc_score, roc_curve
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.api import OLS, Logit, add_constant
import statsmodels.api as sm
import warnings
# 3. Regressão Linear
## 3.1 Modelo completo
X = df[['mean_concave_points', 'mean_perimeter', 'mean_fractal_dimension',
        'worst_perimeter', 'worst_texture', 'worst_area']]
y = df['target']  # Usando target diretamente (0/1)
X = sm.add_constant(X)

model_ols = OLS(y, X).fit()
print(model_ols.summary())

"""fator de variância"""

# Fator de Inflação de Variância (VIF)
vif_data = pd.DataFrame()
vif_data["Variável"] = X.columns[1:]
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(1, len(X.columns))]
print("\nFator de Inflação de Variância (VIF):")
print(vif_data)

## 3.2 Modelo simples

model_ols_simples = OLS(y, df[['mean_concave_points']]).fit()
print(model_ols.summary())



plt.figure(figsize=(10, 6))
sns.regplot(x='mean_concave_points', y='target', data=df, ci=95)
plt.ylim(-0.1, 1.1)
plt.title('Relação Linear: Target ~ Mean Concave Points')
plt.xlabel('Mean Concave Points')
plt.ylabel('Target (0=Benigno, 1=Maligno)')
plt.show()

## 3.3 Modelo final simplificado
X_final = df[['mean_concave_points', 'worst_perimeter', 'mean_fractal_dimension']]
X_final = sm.add_constant(X_final)
model_final = OLS(y, X_final).fit()
print(model_final.summary())

"""3 – Construa uma regressão logistica para prever o tipo do tumor, indique as variaveis preditoras e as com significancia marginal neste modelo. Dica utilize o modulo “GLM” do “statsmodels” com reposta binomial. Comente os resultados obtidos.

 import statsmodels.api as sm
res = sm.GLM(y, x, family=sm.families.Binomial()).fit()
 print(res.summary())
"""

# 4. Regressão Logística
## 4.1 Modelo completo
X_logit = df[['mean_concave_points', 'mean_perimeter', 'mean_fractal_dimension',
              'worst_perimeter', 'worst_texture', 'worst_area']]
y_logit = df['target']  # Usando target diretamente
X_logit = sm.add_constant(X_logit)

model_logit_full = Logit(y_logit, X_logit).fit()
print(model_logit_full.summary())

## 4.2 Modelo simplificado
X_logit_final = df[['mean_concave_points', 'worst_perimeter']]
X_logit_final = sm.add_constant(X_logit_final)
model_logit_final = Logit(y_logit, X_logit_final).fit()
print(model_logit_final.summary())

# Curva de Regressão Logística
plt.figure(figsize=(10, 6))
sns.regplot(x='mean_concave_points', y='target', data=df,
            logistic=True, ci=95,
            scatter_kws={'alpha':0.4, 'color':'#0072B2'},
            line_kws={'color':'#D55E00', 'lw':2})
plt.ylim(-0.1, 1.1)
plt.title('Curva de Regressão Logística: Probabilidade de Tumor Maligno')
plt.xlabel('Mean Concave Points')
plt.ylabel('Probabilidade de Tumor Maligno')
plt.show()

# Curva ROC
y_pred_prob = model_logit_final.predict(X_logit_final)
fpr, tpr, _ = roc_curve(y_logit, y_pred_prob)
auc_score = roc_auc_score(y_logit, y_pred_prob)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2,
         label=f'Curva ROC (AUC = {auc_score:.3f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('Curva ROC (Característica Operacional do Receptor)')
plt.legend(loc="lower right")
plt.show()



# 5. Comparação de Modelos
results = pd.DataFrame({
    'Modelo': ['Linear Completo', 'Linear Simplificado', 'Logístico Completo', 'Logístico Simplificado'],
    'Variáveis': [6, 3, 6, 2],
    'R2_AIC': [model_ols.rsquared_adj, model_final.rsquared_adj,
               model_logit_full.aic, model_logit_final.aic],
    'AUC': [np.nan, np.nan,
            roc_auc_score(y_logit, model_logit_full.predict(X_logit)),
            auc_score]
})

print("\nComparação de Modelos:")
print(results)